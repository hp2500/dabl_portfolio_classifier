{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import dabl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import io\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn_extra.fast_kernel import FKCEigenPro\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "# set api key\n",
    "openml.config.apikey = open('.key', 'r').readline().strip('\\n')\n",
    "\n",
    "# get all supervised classification tasks \n",
    "tasks_all = openml.tasks.list_tasks(task_type_id=1, output_format='dataframe', tag = 'OpenML-CC18')\n",
    "tasks_all = tasks_all.drop([3573, 146825, 167121, 167124])\n",
    "\n",
    "# set openml cache\n",
    "# openml.config.cache_directory = os.path.expanduser('/scratch/hp2500/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-25 07:19:20.808705\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over tasks with successive halving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try task 9971 ...\n",
      "Time: 1566684882.486909\n",
      "Run successive halving...\n"
     ]
    }
   ],
   "source": [
    "# randomly pick tasks in infinite loop\n",
    "while 1:\n",
    "    \n",
    "    # sample task \n",
    "    i = tasks_all['tid'].sample(1).iloc[0]\n",
    "    \n",
    "    # print feedback\n",
    "    print('Try task', i, '...')\n",
    "    \n",
    "    try:\n",
    "        # measure runtime t0\n",
    "        t0 = time()\n",
    "        print('Time:', t0)\n",
    "\n",
    "        # get task\n",
    "        task = openml.tasks.get_task(i)\n",
    "\n",
    "        # get dataset object \n",
    "        data = openml.datasets.get_dataset(task.dataset_id)\n",
    "\n",
    "        # get relevant info from dataset object\n",
    "        X, y, categorical_indicator, attribute_names = data.get_data(dataset_format='array',\n",
    "                                                                    target=data.default_target_attribute)\n",
    "        \n",
    "        X = pd.DataFrame(X, columns=attribute_names)\n",
    "        y = pd.Series(y)\n",
    "        \n",
    "        cat = categorical_indicator\n",
    "        num = [not k for k in categorical_indicator]\n",
    "\n",
    "        \n",
    "        numeric_transformer = make_pipeline(#SimpleImputer(strategy='median'), \n",
    "                                            StandardScaler())\n",
    "\n",
    "        categorical_transformer = make_pipeline(#SimpleImputer(strategy='most_frequent'),\n",
    "                                                OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numeric_transformer, num),\n",
    "        ('cat', categorical_transformer, cat)])\n",
    "               \n",
    "        # define classifier\n",
    "        clf = SVC()\n",
    "        \n",
    "        if not any(categorical_indicator):\n",
    "            pipe = make_pipeline(SimpleImputer(strategy='median'), StandardScaler(), clf)\n",
    "        elif all(categorical_indicator):\n",
    "            pipe = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder(handle_unknown='ignore'), clf)\n",
    "        else:\n",
    "            pipe = make_pipeline(SimpleImputer(strategy='most_frequent'), preprocessor, clf)\n",
    "        \n",
    "        # define parameter grid\n",
    "        param_grid = {'svc__gamma': np.logspace(-10,10,21),\n",
    "                      'svc__C': np.logspace(-10,10,21),\n",
    "                      'svc__degree': [2, 3, 4],\n",
    "                      'svc__kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]}\n",
    "\n",
    "        # print feedbackack\n",
    "        print('Run successive halving...')\n",
    "        \n",
    "        # instantiate successive halfing with samples\n",
    "        sh = dabl.search.RandomSuccessiveHalving(pipe, \n",
    "                                                param_distributions=param_grid,\n",
    "                                                budget_on='n_samples',\n",
    "                                                aggressive_elimination = True)\n",
    "\n",
    "        # fit model \n",
    "        sh_fit = sh.fit(X, y)\n",
    "\n",
    "        # print feedbackack\n",
    "        print('Create openml run...')\n",
    "\n",
    "        # instantiate new classifier with best parameters \n",
    "        pipe.set_params(**(sh_fit.best_params_))\n",
    "        \n",
    "        # run best model on the task\n",
    "        run = openml.runs.run_model_on_task(pipe, task)\n",
    "\n",
    "        # print feedbackack\n",
    "        print('Publish openml run...')\n",
    "\n",
    "        # publish the run\n",
    "        run.publish()\n",
    "\n",
    "        # measure runtime t1\n",
    "        t1 = time()\n",
    "\n",
    "        # print feedback\n",
    "        print('Runtime:', t1-t0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('An error occurred...')\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        # print feedback\n",
    "        print('View run online: https://www.openml.org/r/' + str(run.run_id))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
