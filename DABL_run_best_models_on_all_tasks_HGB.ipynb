{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best runs on all tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import openml\n",
    "from openml import tasks, flows, runs\n",
    "import sklearn\n",
    "from sklearn import feature_selection\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from collections import OrderedDict, Counter\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "# enable hgb\n",
    "enable_hist_gradient_boosting\n",
    "\n",
    "# set api key\n",
    "openml.config.apikey = open('.key', 'r').readline().strip('\\n')\n",
    "\n",
    "# set openml cache\n",
    "# openml.config.cache_directory = os.path.expanduser('/scratch/hp2500/cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get OpenML runs for HGB flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get HGB evals\n",
    "evals = openml.evaluations.list_evaluations('area_under_roc_curve', \n",
    "                                            uploader = [8323], \n",
    "                                            flow=[12736],\n",
    "                                            #tag = 'OpenML-CC18',\n",
    "                                            output_format='dataframe'\n",
    "                                            )\n",
    "\n",
    "# rank evaluations\n",
    "evals['rank'] = evals.groupby('task_id')['value'].rank('dense', ascending=False)\n",
    "\n",
    "# get best evaluations\n",
    "best_evals = evals.loc[evals['rank'] <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all supervised classification tasks \n",
    "tasks_all = openml.tasks.list_tasks(task_type_id=1, output_format='dataframe', tag = 'OpenML-CC18')\n",
    "\n",
    "# drop impossible task\n",
    "tasks_all = tasks_all.drop(index=167121, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over all tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model for run 10228542 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10228544 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10228549 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10228566 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10228568 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10228573 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10228581 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10228592 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229016 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229243 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229255 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229266 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229287 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229348 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229352 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229353 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229372 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229411 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229427 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229443 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229463 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229484 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229495 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229508 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229509 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229513 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229541 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229547 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229548 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229550 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229569 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229579 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229584 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229602 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229631 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229635 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229641 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229682 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229736 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229758 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229794 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229802 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229810 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229813 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229832 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229848 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229909 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229915 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229954 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229978 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229981 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229984 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10229994 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230007 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230039 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230095 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230106 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230110 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230184 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230212 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230225 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230233 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230244 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230252 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230263 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230275 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230283 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230300 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230364 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230368 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230383 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230403 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230409 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230417 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230459 on task 9952\n",
      "Publish openml run...\n",
      "Fit model for run 10230463 on task 9952\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-3d3c211e403f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m# run best model on the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model_on_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;31m# print feedbackack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/openml/runs/functions.py\u001b[0m in \u001b[0;36mrun_model_on_task\u001b[0;34m(model, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow, return_flow)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0madd_local_measures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_local_measures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mupload_flow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupload_flow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_flow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/openml/runs/functions.py\u001b[0m in \u001b[0;36mrun_flow_on_task\u001b[0;34m(flow, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mextension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0madd_local_measures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_local_measures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     )\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/openml/runs/functions.py\u001b[0m in \u001b[0;36m_run_task_get_arffcontent\u001b[0;34m(flow, model, task, extension, add_local_measures)\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mrep_no\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrep_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mfold_no\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         )\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/openml/extensions/sklearn/extension.py\u001b[0m in \u001b[0;36m_run_model_on_fold\u001b[0;34m(self, model, task, X_train, rep_no, fold_no, y_train, X_test)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;31m# Also seed CV objects!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCrossValidator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'random_state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0ml2_regularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_regularization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                     shrinkage=self.learning_rate)\n\u001b[0;32m--> 258\u001b[0;31m                 \u001b[0mgrower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0macc_apply_split_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_apply_split_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py\u001b[0m in \u001b[0;36mgrow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;34m\"\"\"Grow the tree, from root to leaves.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplittable_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_intilialize_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhessians\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhessians_are_constant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py\u001b[0m in \u001b[0;36msplit_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0msmallest_child\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistograms\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                 self.histogram_builder.compute_histograms_brute(\n\u001b[0;32m--> 374\u001b[0;31m                     smallest_child.sample_indices)\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0mlargest_child\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistograms\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                 self.histogram_builder.compute_histograms_subtraction(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop over tasks\n",
    "while 1:\n",
    "    \n",
    "        # sample task \n",
    "        i = tasks_all['tid'].sample(1).iloc[0]\n",
    "\n",
    "        # get task\n",
    "        task = openml.tasks.get_task(i)\n",
    "\n",
    "        # loop over runs\n",
    "        for j in best_evals.run_id:\n",
    "\n",
    "            # feedback\n",
    "            print('Fit model for run', j, 'on task', i)\n",
    "\n",
    "            # initialize model with parameters from run\n",
    "            model = openml.runs.initialize_model_from_run(j)\n",
    "\n",
    "\n",
    "            try: \n",
    "                # run best model on the task\n",
    "                run = openml.runs.run_model_on_task(model, task)\n",
    "\n",
    "                # print feedbackack\n",
    "                print('Publish openml run...')\n",
    "\n",
    "                # push tag\n",
    "                #run.push_tag('best_models')\n",
    "\n",
    "                # publish the run \n",
    "                run.publish()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
